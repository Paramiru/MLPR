{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-chart",
   "metadata": {},
   "source": [
    "# Question 1: Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-retrieval",
   "metadata": {},
   "source": [
    "## Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_data = np.load(\"amp_data.npz\")[\"amp_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot a line graph showing the sequence in amp_data\"\"\"\n",
    "def plot_line_graph(data: np.array):\n",
    "    tt = np.arange(len(data))\n",
    "    plt.clf()\n",
    "    plt.plot(tt, data)\n",
    "    plt.show()\n",
    "plot_line_graph(amp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amplitude_histogram(data, bins=100):\n",
    "    bins = len(data) / 1000 if (bins == 100) else bins\n",
    "    data = np.array(data)\n",
    "    plt.clf()\n",
    "    plt.hist(data, bins=100)\n",
    "    plt.show()\n",
    "plot_amplitude_histogram(amp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-delaware",
   "metadata": {},
   "source": [
    "## Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b611592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(arr):\n",
    "    size = len(arr)\n",
    "    train_amount, val_amount, test_amount = 0.7, 0.15, 0.15\n",
    "    train_split = int(size * train_amount)\n",
    "    val_split = int(size * val_amount) + train_split\n",
    "    \n",
    "    X_shuf_train = arr[:train_split][:, :20]\n",
    "    y_shuf_train = arr[:train_split][:, 20]\n",
    "    \n",
    "    X_shuf_val = arr[train_split:val_split][:, :20]\n",
    "    y_shuf_val = arr[train_split:val_split][:, 20]\n",
    "    \n",
    "    X_shuf_test = arr[val_split:][:, :20]\n",
    "    y_shuf_test = arr[val_split:][:, 20]\n",
    "    \n",
    "    return X_shuf_train, y_shuf_train, X_shuf_val, y_shuf_val, X_shuf_test, y_shuf_test\n",
    "    \n",
    "\n",
    "def create_six_arrays(data):\n",
    "    data = np.array(data)[:, None]\n",
    "    \"\"\"remove last values so it can be mapped into a Cx21 matrix\"\"\"\n",
    "    values_to_remove = data.shape[0] % 21\n",
    "    data = data[:-values_to_remove].reshape(-1, 21)\n",
    "    \"\"\"Shuffle the rows of the matrix\"\"\"\n",
    "    np.random.shuffle(data)\n",
    "    return split_array(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0ec0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuf_train, y_shuf_train, X_shuf_val, y_shuf_val, X_shuf_test, y_shuf_test = create_six_arrays(amp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79738b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1123775, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shuf_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-thanks",
   "metadata": {},
   "source": [
    "# Question 2: Curve fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-heavy",
   "metadata": {},
   "source": [
    "## Part a\n",
    "Code for a plot that shows 20 training points, a test point, a straight line fit, and a quartic fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1/20\n",
    "xx = np.arange(0, 1, step_size)[:, None]\n",
    "\n",
    "yy = X_shuf_train[0]\n",
    "test_point = y_shuf_train[0]\n",
    "\n",
    "linear_xx = np.hstack([xx, np.ones(xx.shape[0])[:, None]])\n",
    "linear_weights = np.linalg.lstsq(linear_xx, yy, rcond=None)[0]\n",
    "\n",
    "quartic_xx = xx ** np.arange(5)\n",
    "quartic_weights = np.linalg.lstsq(quartic_xx, yy, rcond=None)[0]\n",
    "\n",
    "\"\"\"Add prediction to the plot by using 21 times from 0 to 1.05 with step size 1/20\"\"\"\n",
    "times = np.arange(0, 1 + step_size, step_size)\n",
    "quartic_xx_with_prediction = times[:,None] ** np.arange(5)\n",
    "linear_xx_with_prediction = np.vstack([times, np.ones(len(times))]).T\n",
    "\n",
    "plt.plot(xx, yy, label=\"Original data\")\n",
    "plt.scatter(1, test_point, color=\"red\", label=\"Last datapoint\")\n",
    "\"\"\"\n",
    "Change linear/quartic_xx to linear/quartic_xx_with_prediction\n",
    "and xx to times for getting the prediction in the plot \n",
    "\"\"\"\n",
    "plt.plot(xx, np.dot(linear_xx, linear_weights), color=\"red\", label=\"Straight line fit\")\n",
    "# plt.plot(times, np.dot(linear_xx_with_prediction, linear_weights), color=\"red\", label=\"Straight line fit\")\n",
    "plt.plot(xx, np.dot(quartic_xx, quartic_weights), color=\"orange\", label=\"Quartic fit\")\n",
    "# plt.plot(times, np.dot(quartic_xx_with_prediction, quartic_weights), color=\"orange\", label=\"Quartic fit\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-produce",
   "metadata": {},
   "source": [
    "## Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-acrobat",
   "metadata": {},
   "source": [
    "We put equal weight to each residual, no matter how long it happened in the past. Closer datapoints are more important and will lose importance if we look too much into the past. A longer context for the quartic fit will be better as this will prevent overfitting, instead of using just two datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-mexico",
   "metadata": {},
   "source": [
    "## Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-baltimore",
   "metadata": {},
   "source": [
    "After trying third, fourth and fifth oder polynomial a third order polynomial with a bias fits the data best assuming a context length of 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-patrol",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-aurora",
   "metadata": {},
   "source": [
    "## Part b i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decimal-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Phi(C, K):\n",
    "    times = np.arange(0, 1, step=1/20)[:,None][-C:]\n",
    "    return times ** np.arange(K)\n",
    "\n",
    "C = 20\n",
    "K = 2\n",
    "design = Phi(C, K)\n",
    "# print(design)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-button",
   "metadata": {},
   "source": [
    "## Part b ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vv(C, K):\n",
    "    phi_matrix = Phi(C, K)\n",
    "    phi_t_1 = np.ones((K, 1))\n",
    "    return phi_matrix @ np.linalg.inv( (phi_matrix.T @ phi_matrix) ).T @ phi_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_from_v():\n",
    "    v = make_vv(C, K)\n",
    "    v.shape\n",
    "    print(v.T @ X_shuf_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417709de",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction_from_v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_prediction():\n",
    "    times = np.arange(0, 1 + step_size, step_size)\n",
    "    linear_x = np.vstack([times, np.ones(len(times))]).T\n",
    "    linear_weights = np.linalg.lstsq(linear_xx, yy, rcond=None)[0]\n",
    "    print(np.dot(linear_x, linear_weights)[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a6289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quartic_prediction():\n",
    "    step_size = 1/20\n",
    "    times = np.arange(0, 1 + step_size, step_size)\n",
    "    quartic_xx_with_prediction = times[:,None] ** np.arange(5)\n",
    "    print(np.dot(quartic_xx_with_prediction, quartic_weights)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-alias",
   "metadata": {},
   "source": [
    "## Part b iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1/20\n",
    "xx = np.arange(0, 1, step_size)[:, None]\n",
    "xx_with_prediction = np.arange(0, 1 + step_size, step_size)[:,None]\n",
    "\n",
    "\n",
    "def get_linear_prediction_from_v(datapoints: np.array):\n",
    "    C, K = 20, 2\n",
    "    v = make_vv(C, K)\n",
    "    prediction = (v.T @ datapoints)[0]\n",
    "    # Print prediction by using vector v\n",
    "    print(f'Linear prediction by using vector v: {prediction}')\n",
    "    \n",
    "def get_quartic_prediction_from_v(datapoints: np.array):\n",
    "    C, K = 20, 5\n",
    "    v = make_vv(C, K)\n",
    "    prediction = (v.T @ datapoints)[0]\n",
    "    # Print prediction by using vector v\n",
    "    print(f'Quartic prediction by using vector v: {(v.T @ datapoints)[0]}')\n",
    "    \n",
    "def get_linear_prediction(datapoints: np.array):\n",
    "    linear_xx = np.hstack([xx, np.ones(xx.shape[0])[:, None]])\n",
    "    linear_weights = np.linalg.lstsq(linear_xx, datapoints, rcond=None)[0]\n",
    "    linear_xx_with_prediction = xx_with_prediction ** np.arange(2)\n",
    "    # Print linear prediction\n",
    "    print(f'Linear prediction: {np.dot(linear_xx_with_prediction, linear_weights)[-1]}')\n",
    "\n",
    "def get_quartic_prediction(datapoints: np.array):\n",
    "    quartic_xx = xx ** np.arange(5)\n",
    "    quartic_weights = np.linalg.lstsq(quartic_xx, datapoints, rcond=None)[0]\n",
    "    quartic_xx_with_prediction = xx_with_prediction ** np.arange(5)\n",
    "    # Print quartic prediction\n",
    "    print(f'Quartic prediction: {np.dot(quartic_xx_with_prediction, quartic_weights)[-1]}')\n",
    "\n",
    "\n",
    "\n",
    "get_linear_prediction_from_v(X_shuf_train[0])\n",
    "get_linear_prediction(X_shuf_train[0])\n",
    "get_quartic_prediction_from_v(X_shuf_train[0])\n",
    "get_quartic_prediction(X_shuf_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279bc0f9",
   "metadata": {},
   "source": [
    "# Question 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4d30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_from_v(datapoints: np.array, K: int, C: int):\n",
    "    v = make_vv(C, K)\n",
    "    prediction = (v.T @ datapoints).T\n",
    "    # Print prediction by using vector v\n",
    "    # print(f'Prediction by using vector v: {prediction}')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cfe3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_true, y_pred):\n",
    "    return sum((y_true - y_pred)**2) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = get_prediction_from_v(X_shuf_train.T, K=5, C=20)\n",
    "# y_true = y_shuf_train.reshape(y_pred.shape)\n",
    "y_true = y_shuf_train[:, None]\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_square_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfba47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_values_for_k_and_C():\n",
    "    y_true = y_shuf_train[:, None]\n",
    "    minimum = {'error': float(\"inf\"), 'K':-1, 'C':-1}\n",
    "    \n",
    "    def mean_square_error(y_true, y_pred):\n",
    "        return sum((y_true - y_pred)**2) / len(y_true)\n",
    "\n",
    "    for C in range(1, 21):\n",
    "        for K in range(1, 21):\n",
    "            y_pred = get_prediction_from_v(X_shuf_train.T[-C:], K=K, C=C)\n",
    "            error = mean_square_error(y_true, y_pred)\n",
    "            if error < minimum['error']:\n",
    "                minimum['error'] = error\n",
    "                minimum['K'] = K\n",
    "                minimum['C'] = C\n",
    "                \n",
    "    print(minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7108b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_square_error(dataset: np.array, y_true: np.array):\n",
    "    K, C = 2, 2\n",
    "    y_pred = get_prediction_from_v(dataset.T[-C:], K, C)\n",
    "    error = mean_square_error(y_true, y_pred)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19c6c001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction by using vector v: [[-0.00244141]\n",
      " [-0.01095581]\n",
      " [ 0.1027832 ]\n",
      " ...\n",
      " [ 0.01971436]\n",
      " [-0.0138855 ]\n",
      " [-0.03665161]]\n",
      "[1.35997854e-05]\n"
     ]
    }
   ],
   "source": [
    "get_mean_square_error(X_shuf_train, y_shuf_train[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b375e057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction by using vector v: [[-0.03182983]\n",
      " [ 0.03692627]\n",
      " [ 0.01916504]\n",
      " ...\n",
      " [-0.01831055]\n",
      " [ 0.05322266]\n",
      " [ 0.00250244]]\n",
      "[1.34041439e-05]\n"
     ]
    }
   ],
   "source": [
    "get_mean_square_error(X_shuf_val, y_shuf_val[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37e7738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction by using vector v: [[-0.00448608]\n",
      " [ 0.02804565]\n",
      " [ 0.0345459 ]\n",
      " ...\n",
      " [-0.00308228]\n",
      " [-0.03033447]\n",
      " [ 0.0553894 ]]\n",
      "[1.33191438e-05]\n"
     ]
    }
   ],
   "source": [
    "get_mean_square_error(X_shuf_test, y_shuf_test[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a189c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_4a():\n",
    "    y_true = y_shuf_test[:, None]\n",
    "    for C in range(1, 21):\n",
    "        training_error = get_mean_square_error_v2(X_shuf_train, y_shuf_train[:,None], C)[0]\n",
    "        validation_error = get_mean_square_error_v2(X_shuf_val, y_shuf_val[:,None], C)[0]\n",
    "        print(f'Training error: {training_error} \\t Validation error: {validation_error}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "350007c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Phi_v2(C):\n",
    "    return np.arange(0, 1, step=1/20)[:,None][-C:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22309436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vv_v2(C, K=1):\n",
    "    phi_matrix = Phi_v2(C)\n",
    "    phi_t_1 = np.ones((K, 1))\n",
    "    return phi_matrix @ np.linalg.inv( (phi_matrix.T @ phi_matrix) ).T @ phi_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac325ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_square_error_v2(dataset: np.array, y_true: np.array, C):\n",
    "    y_pred = get_prediction_from_v_v2(dataset.T[-C:], C)\n",
    "    error = mean_square_error(y_true, y_pred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82878f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_from_v_v2(datapoints: np.array, C: int):\n",
    "    v = make_vv_v2(C)\n",
    "    prediction = (v.T @ datapoints).T\n",
    "    # Print prediction by using vector v\n",
    "    # print(f'Prediction by using vector v: {prediction}')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee734c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 4.3805726298583096e-05 \t Validation error: 4.3155562983714066e-05\n",
      "Training error: 9.156205675538368e-05 \t Validation error: 9.046011596448667e-05\n",
      "Training error: 0.00015072534070581978 \t Validation error: 0.0001498783601652463\n",
      "Training error: 0.00021816882764881304 \t Validation error: 0.00021818975231687534\n",
      "Training error: 0.00029087980675379687 \t Validation error: 0.0002918703095280602\n",
      "Training error: 0.0003666200848423686 \t Validation error: 0.00036862895809018805\n",
      "Training error: 0.0004433117623161807 \t Validation error: 0.0004465939319481955\n",
      "Training error: 0.0005192667838785514 \t Validation error: 0.0005240006405638587\n",
      "Training error: 0.0005933912463590216 \t Validation error: 0.0005993573198329325\n",
      "Training error: 0.0006650349516162934 \t Validation error: 0.0006719638801927429\n",
      "Training error: 0.0007337772834805714 \t Validation error: 0.0007415405710695369\n",
      "Training error: 0.0007991010762935496 \t Validation error: 0.0008076319828919448\n",
      "Training error: 0.0008603606120877682 \t Validation error: 0.0008695627491266168\n",
      "Training error: 0.0009166858953000835 \t Validation error: 0.0009264822301625135\n",
      "Training error: 0.0009669660877814765 \t Validation error: 0.0009773119464959335\n",
      "Training error: 0.001009915932372654 \t Validation error: 0.0010207283975163315\n",
      "Training error: 0.0010441355837679785 \t Validation error: 0.0010552950932441816\n",
      "Training error: 0.0010681852952451392 \t Validation error: 0.0010795541830757648\n",
      "Training error: 0.0010807355749539228 \t Validation error: 0.001092199840102262\n",
      "Training error: 0.0010807355749539226 \t Validation error: 0.001092199840102262\n"
     ]
    }
   ],
   "source": [
    "question_4a()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
